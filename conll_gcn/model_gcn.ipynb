{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dropout, Dense, Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import pickle as pkl \n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from layers.graph import SpectralGraphConvolution\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_labels(labels):\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i][0] == \"I\":\n",
    "            if i == 0 or labels[i-1][2:] != labels[i][2:]:\n",
    "                labels[i] = \"B-{}\".format(labels[i][2:])\n",
    "    return labels\n",
    "\n",
    "\n",
    "def decode_labels(labels, idx2label):\n",
    "    labels = np.array(labels)\n",
    "    prediction_indices = labels.argmax(axis=1)\n",
    "    prediction_labels = [idx2label[i] for i in prediction_indices]\n",
    "    return prediction_labels\n",
    "\n",
    "\n",
    "def predict_labels(predictions, actuals, idx2label):\n",
    "    predictions_labels = []\n",
    "    actuals_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "#     for i in range(predictions.shape[0]):\n",
    "        prediction = predictions[i]\n",
    "        actual = actuals[i]\n",
    "        prediction_labels = decode_labels(prediction, idx2label)\n",
    "        prediction_labels = fix_labels(prediction_labels)\n",
    "        actual_labels = decode_labels(actual, idx2label)\n",
    "        predictions_labels.append(prediction_labels)\n",
    "        actuals_labels.append(actual_labels)\n",
    "    return predictions_labels, actuals_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_true, y_pred):\n",
    "        ## calc metric\n",
    "    num_proposed = sum(1 for n in y_pred if n != 'O')\n",
    "    num_correct = 0\n",
    "    for i,j in zip(y_true,y_pred):\n",
    "        if i != 'O' and i == j:\n",
    "            num_correct +=1\n",
    "    num_gold = sum(1 for n in y_true if n != 'O')\n",
    "    print(\"num_proposed: \", num_proposed)\n",
    "    print(\"num_correct: \", num_correct)\n",
    "    print(\"num_gold: \", num_gold)\n",
    "    try:\n",
    "        precision = num_correct / num_proposed\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1.0\n",
    "\n",
    "    try:\n",
    "        recall = num_correct / num_gold\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1.0\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        if precision*recall==0:\n",
    "            f1=1.0\n",
    "        else:\n",
    "            f1=0\n",
    "    final = \".P%.2f_R%.2f_F%.2f\" %(precision, recall, f1)\n",
    "    print(\"precision=%.4f\"%precision)\n",
    "    print(\"recall=%.4f\"%recall)\n",
    "    print(\"f1=%.4f\"%f1)\n",
    "    print(\"final \",final)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_metric(y_true, y_pred):\n",
    "        ## calc metric\n",
    "    y_pred, y_true = predict_labels(\n",
    "        y_pred, y_true, meta['idx2label'])\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = [x.split('-')[1] if '-' in x else x for x in y_pred[i]]\n",
    "    for i in range(len(y_true)):\n",
    "        y_true[i] = [x.split('-')[1] if '-' in x else x for x in y_true[i]]\n",
    "    \n",
    "    gt = []\n",
    "    pr = []\n",
    "    for i in range(len(y_pred)):\n",
    "        gt.extend(y_pred[i])\n",
    "    for i in range(len(y_true)):\n",
    "        pr.extend(y_true[i])\n",
    "        \n",
    "    num_proposed = sum(1 for n in pr if n != 'O')\n",
    "    num_correct = 0\n",
    "    for i,j in zip(gt,pr):\n",
    "        if i != 'O' and i == j:\n",
    "            num_correct +=1\n",
    "    num_gold = sum(1 for n in gt if n != 'O')\n",
    "    try:\n",
    "        precision = num_correct / num_proposed\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1.0\n",
    "\n",
    "    try:\n",
    "        recall = num_correct / num_gold\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1.0\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        if precision*recall==0:\n",
    "            f1=1.0\n",
    "        else:\n",
    "            f1=0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'conll2003'\n",
    "EPOCHS = 4\n",
    "LR = 0.001\n",
    "L2 = 0\n",
    "DO = 0.5\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loading embedding matrix...\n",
      "Processing dataset...\n",
      "Number of nodes: 124\n",
      "Number of relations: 44\n",
      "Number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "\n",
    "A, X, Y, meta = pkl.load(open('pkl/' + DATASET + '.pkl', 'rb'))\n",
    "\n",
    "print(\"Loading embedding matrix...\")\n",
    "\n",
    "embedding_matrix = pkl.load(\n",
    "    open('pkl/' + DATASET + '.embedding_matrix.pkl', 'rb'))\n",
    "\n",
    "print(\"Processing dataset...\")\n",
    "\n",
    "val_y = load_output(A, X, Y, 'val')\n",
    "test_y = load_output(A, X, Y, 'test')\n",
    "\n",
    "num_nodes = A['train'][0][0].shape[0]\n",
    "num_relations = len(A['train'][0]) - 1\n",
    "num_labels = len(meta['label2idx'])\n",
    "\n",
    "print(\"Number of nodes: {}\".format(num_nodes))\n",
    "print(\"Number of relations: {}\".format(num_relations))\n",
    "print(\"Number of classes: {}\".format(num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model inputs\n",
    "X_in = Input(shape=(num_nodes, ))\n",
    "A_in = [Input(shape=(num_nodes, num_nodes)) for _ in range(num_relations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 124)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 124, 300)     442806300   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           (None, 124, 124)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spectral_graph_convolution_1 (S (None, 124, 256)     7020544     embedding_1[0][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "                                                                 input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "                                                                 input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "                                                                 input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "                                                                 input_43[0][0]                   \n",
      "                                                                 input_44[0][0]                   \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 124, 256)     0           spectral_graph_convolution_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spectral_graph_convolution_2 (S (None, 124, 256)     5995520     dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "                                                                 input_25[0][0]                   \n",
      "                                                                 input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "                                                                 input_31[0][0]                   \n",
      "                                                                 input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "                                                                 input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "                                                                 input_43[0][0]                   \n",
      "                                                                 input_44[0][0]                   \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 124, 256)     0           spectral_graph_convolution_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 124, 8)       2056        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 455,824,420\n",
      "Trainable params: 13,018,120\n",
      "Non-trainable params: 442,806,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Define model\")\n",
    "# Define model architecture\n",
    "X_embedding = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[\n",
    "                        embedding_matrix], trainable=False)(X_in)\n",
    "H = SpectralGraphConvolution(256, activation='relu')([X_embedding] + A_in)\n",
    "H = Dropout(DO)(H)\n",
    "H = SpectralGraphConvolution(256, activation='relu')([H] + A_in)\n",
    "H = Dropout(DO)(H)\n",
    "output = Dense(num_labels, activation='softmax')(H)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in] + A_in, outputs=output)\n",
    "model.compile(metrics=['acc'],loss='categorical_crossentropy', optimizer=Adam(lr=LR))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [EarlyStopping(monitor='f1_metric', patience=2, verbose=0),\n",
    "#              ModelCheckpoint(filepath='model.{loss:.2f}.h5', monitor='f1_metric', save_best_only=True, verbose=0)\n",
    "#             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EPOCH 1 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 139s 121ms/step - loss: 0.0753 - acc: 0.9888\n",
      "216/216 [==============================] - 14s 65ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9968688929547209\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.92      0.90      0.91      2144\n",
      "       MISC       0.70      0.92      0.80       965\n",
      "          O       1.00      1.00      1.00    420276\n",
      "        ORG       0.82      0.80      0.81      2121\n",
      "        PER       0.94      0.97      0.95      3038\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  7472\n",
      "num_gold:  8268\n",
      "precision=0.8706\n",
      "recall=0.9037\n",
      "f1=0.8868\n",
      "final  .P0.87_R0.90_F0.89\n",
      "230/230 [==============================] - 14s 60ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9955219840668679\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.88      0.83      0.85      2036\n",
      "       MISC       0.63      0.77      0.69       743\n",
      "          O       1.00      1.00      1.00    448245\n",
      "        ORG       0.77      0.72      0.75      2660\n",
      "        PER       0.90      0.95      0.93      2636\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6682\n",
      "num_gold:  8075\n",
      "precision=0.8253\n",
      "recall=0.8275\n",
      "f1=0.8264\n",
      "final  .P0.83_R0.83_F0.83\n",
      "=== EPOCH 2 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 123s 107ms/step - loss: 0.0179 - acc: 0.9955\n",
      "216/216 [==============================] - 13s 62ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9979975335656358\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.96      0.93      0.94      2170\n",
      "       MISC       0.79      0.95      0.86      1053\n",
      "          O       1.00      1.00      1.00    420237\n",
      "        ORG       0.87      0.91      0.89      1974\n",
      "        PER       0.97      0.98      0.97      3110\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  7845\n",
      "num_gold:  8307\n",
      "precision=0.9140\n",
      "recall=0.9444\n",
      "f1=0.9290\n",
      "final  .P0.91_R0.94_F0.93\n",
      "230/230 [==============================] - 14s 61ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9963693007624613\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.83      0.87      2114\n",
      "       MISC       0.68      0.81      0.74       762\n",
      "          O       1.00      1.00      1.00    448408\n",
      "        ORG       0.77      0.82      0.80      2330\n",
      "        PER       0.93      0.95      0.94      2706\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6859\n",
      "num_gold:  7912\n",
      "precision=0.8472\n",
      "recall=0.8669\n",
      "f1=0.8569\n",
      "final  .P0.85_R0.87_F0.86\n",
      "=== EPOCH 3 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 122s 106ms/step - loss: 0.0134 - acc: 0.9964\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9985545252120531\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.96      0.96      0.96      2092\n",
      "       MISC       0.84      0.96      0.89      1111\n",
      "          O       1.00      1.00      1.00    420144\n",
      "        ORG       0.92      0.92      0.92      2078\n",
      "        PER       0.98      0.99      0.98      3119\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8067\n",
      "num_gold:  8400\n",
      "precision=0.9399\n",
      "recall=0.9604\n",
      "f1=0.9500\n",
      "final  .P0.94_R0.96_F0.95\n",
      "230/230 [==============================] - 14s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9966658918406022\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.87      0.88      1962\n",
      "       MISC       0.69      0.82      0.75       763\n",
      "          O       1.00      1.00      1.00    448374\n",
      "        ORG       0.83      0.82      0.82      2520\n",
      "        PER       0.93      0.96      0.94      2701\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6983\n",
      "num_gold:  7946\n",
      "precision=0.8625\n",
      "recall=0.8788\n",
      "f1=0.8706\n",
      "final  .P0.86_R0.88_F0.87\n",
      "=== EPOCH 4 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0112 - acc: 0.9969\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9987824396030676\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.97      0.96      0.97      2118\n",
      "       MISC       0.86      0.97      0.91      1118\n",
      "          O       1.00      1.00      1.00    420127\n",
      "        ORG       0.93      0.94      0.93      2056\n",
      "        PER       0.98      0.99      0.99      3125\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8139\n",
      "num_gold:  8417\n",
      "precision=0.9483\n",
      "recall=0.9670\n",
      "f1=0.9575\n",
      "final  .P0.95_R0.97_F0.96\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9967138129333862\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.86      0.88      2010\n",
      "       MISC       0.69      0.84      0.76       754\n",
      "          O       1.00      1.00      1.00    448417\n",
      "        ORG       0.81      0.84      0.82      2417\n",
      "        PER       0.94      0.95      0.94      2722\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6973\n",
      "num_gold:  7903\n",
      "precision=0.8613\n",
      "recall=0.8823\n",
      "f1=0.8717\n",
      "final  .P0.86_R0.88_F0.87\n",
      "=== EPOCH 5 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0099 - acc: 0.9972\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9990182327245889\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.98      0.97      0.98      2122\n",
      "       MISC       0.88      0.97      0.92      1144\n",
      "          O       1.00      1.00      1.00    420129\n",
      "        ORG       0.93      0.97      0.95      2004\n",
      "        PER       0.99      0.99      0.99      3145\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8212\n",
      "num_gold:  8415\n",
      "precision=0.9568\n",
      "recall=0.9759\n",
      "f1=0.9662\n",
      "final  .P0.96_R0.98_F0.97\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968154242120799\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.86      0.88      2015\n",
      "       MISC       0.70      0.84      0.76       760\n",
      "          O       1.00      1.00      1.00    448500\n",
      "        ORG       0.79      0.86      0.82      2297\n",
      "        PER       0.94      0.95      0.95      2748\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6954\n",
      "num_gold:  7820\n",
      "precision=0.8589\n",
      "recall=0.8893\n",
      "f1=0.8738\n",
      "final  .P0.86_R0.89_F0.87\n",
      "=== EPOCH 6 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0088 - acc: 0.9975\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9991533372502256\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.98      0.97      0.98      2117\n",
      "       MISC       0.89      0.98      0.93      1159\n",
      "          O       1.00      1.00      1.00    420047\n",
      "        ORG       0.96      0.96      0.96      2086\n",
      "        PER       0.99      0.99      0.99      3135\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8286\n",
      "num_gold:  8497\n",
      "precision=0.9654\n",
      "recall=0.9752\n",
      "f1=0.9703\n",
      "final  .P0.97_R0.98_F0.97\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9967171991147269\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.86      0.88      2024\n",
      "       MISC       0.70      0.85      0.77       749\n",
      "          O       1.00      1.00      1.00    448345\n",
      "        ORG       0.82      0.82      0.82      2494\n",
      "        PER       0.93      0.95      0.94      2708\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7008\n",
      "num_gold:  7975\n",
      "precision=0.8656\n",
      "recall=0.8787\n",
      "f1=0.8721\n",
      "final  .P0.87_R0.88_F0.87\n",
      "=== EPOCH 7 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0079 - acc: 0.9978\n",
      "216/216 [==============================] - 12s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9992808670014541\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.97      0.98      2120\n",
      "       MISC       0.91      0.98      0.95      1173\n",
      "          O       1.00      1.00      1.00    420065\n",
      "        ORG       0.96      0.97      0.96      2050\n",
      "        PER       0.99      0.99      0.99      3136\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8323\n",
      "num_gold:  8479\n",
      "precision=0.9697\n",
      "recall=0.9816\n",
      "f1=0.9756\n",
      "final  .P0.97_R0.98_F0.98\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968234511233303\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.86      0.88      2011\n",
      "       MISC       0.69      0.84      0.76       755\n",
      "          O       1.00      1.00      1.00    448434\n",
      "        ORG       0.80      0.85      0.83      2354\n",
      "        PER       0.95      0.95      0.95      2766\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6991\n",
      "num_gold:  7886\n",
      "precision=0.8635\n",
      "recall=0.8865\n",
      "f1=0.8749\n",
      "final  .P0.86_R0.89_F0.87\n",
      "=== EPOCH 8 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0073 - acc: 0.9980\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9993104103596141\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.98      0.99      0.99      2083\n",
      "       MISC       0.91      0.99      0.95      1164\n",
      "          O       1.00      1.00      1.00    420111\n",
      "        ORG       0.95      0.97      0.96      2035\n",
      "        PER       0.99      0.99      0.99      3151\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8317\n",
      "num_gold:  8433\n",
      "precision=0.9690\n",
      "recall=0.9862\n",
      "f1=0.9776\n",
      "final  .P0.97_R0.99_F0.98\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968735139877727\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.89      0.89      1930\n",
      "       MISC       0.69      0.84      0.76       745\n",
      "          O       1.00      1.00      1.00    448507\n",
      "        ORG       0.81      0.85      0.83      2368\n",
      "        PER       0.95      0.95      0.95      2770\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6979\n",
      "num_gold:  7813\n",
      "precision=0.8620\n",
      "recall=0.8933\n",
      "f1=0.8774\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 9 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0066 - acc: 0.9981\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9994343474423613\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.98      0.98      2100\n",
      "       MISC       0.93      0.99      0.96      1196\n",
      "          O       1.00      1.00      1.00    420034\n",
      "        ORG       0.97      0.98      0.97      2065\n",
      "        PER       0.99      0.99      0.99      3149\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8387\n",
      "num_gold:  8510\n",
      "precision=0.9772\n",
      "recall=0.9855\n",
      "f1=0.9813\n",
      "final  .P0.98_R0.99_F0.98\n",
      "230/230 [==============================] - 14s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968952270142382\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.89      1982\n",
      "       MISC       0.70      0.83      0.76       769\n",
      "          O       1.00      1.00      1.00    448408\n",
      "        ORG       0.81      0.85      0.83      2371\n",
      "        PER       0.95      0.95      0.95      2790\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7039\n",
      "num_gold:  7912\n",
      "precision=0.8694\n",
      "recall=0.8897\n",
      "f1=0.8794\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 10 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0062 - acc: 0.9982\n",
      "216/216 [==============================] - 12s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999458145847677\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.99      0.99      2099\n",
      "       MISC       0.94      0.99      0.96      1209\n",
      "          O       1.00      1.00      1.00    420070\n",
      "        ORG       0.96      0.98      0.97      2023\n",
      "        PER       0.99      0.99      0.99      3143\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8380\n",
      "num_gold:  8474\n",
      "precision=0.9763\n",
      "recall=0.9889\n",
      "f1=0.9826\n",
      "final  .P0.98_R0.99_F0.98\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968526726423425\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.89      0.89      1935\n",
      "       MISC       0.71      0.81      0.76       797\n",
      "          O       1.00      1.00      1.00    448545\n",
      "        ORG       0.80      0.87      0.83      2288\n",
      "        PER       0.94      0.95      0.95      2755\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6964\n",
      "num_gold:  7775\n",
      "precision=0.8602\n",
      "recall=0.8957\n",
      "f1=0.8776\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 11 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 122s 105ms/step - loss: 0.0057 - acc: 0.9984\n",
      "216/216 [==============================] - 13s 62ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9995910594534192\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.99      0.99      2094\n",
      "       MISC       0.96      0.99      0.97      1225\n",
      "          O       1.00      1.00      1.00    420018\n",
      "        ORG       0.97      0.98      0.98      2059\n",
      "        PER       0.99      0.99      0.99      3148\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8441\n",
      "num_gold:  8526\n",
      "precision=0.9835\n",
      "recall=0.9900\n",
      "f1=0.9867\n",
      "final  .P0.98_R0.99_F0.99\n",
      "230/230 [==============================] - 14s 60ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.996840294375227\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.88      0.89      1944\n",
      "       MISC       0.73      0.82      0.77       810\n",
      "          O       1.00      1.00      1.00    448444\n",
      "        ORG       0.80      0.86      0.83      2303\n",
      "        PER       0.95      0.94      0.94      2819\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7008\n",
      "num_gold:  7876\n",
      "precision=0.8656\n",
      "recall=0.8898\n",
      "f1=0.8775\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 12 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 123s 107ms/step - loss: 0.0055 - acc: 0.9984\n",
      "216/216 [==============================] - 13s 61ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9995821031652983\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.98      0.99      2119\n",
      "       MISC       0.95      0.99      0.97      1217\n",
      "          O       1.00      1.00      1.00    420014\n",
      "        ORG       0.97      0.99      0.98      2045\n",
      "        PER       1.00      0.99      0.99      3149\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8439\n",
      "num_gold:  8530\n",
      "precision=0.9832\n",
      "recall=0.9893\n",
      "f1=0.9863\n",
      "final  .P0.98_R0.99_F0.99\n",
      "230/230 [==============================] - 14s 63ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968391668142769\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.89      1983\n",
      "       MISC       0.71      0.83      0.77       780\n",
      "          O       1.00      1.00      1.00    448490\n",
      "        ORG       0.79      0.87      0.83      2278\n",
      "        PER       0.94      0.94      0.94      2789\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6981\n",
      "num_gold:  7830\n",
      "precision=0.8623\n",
      "recall=0.8916\n",
      "f1=0.8767\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 13 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 123s 107ms/step - loss: 0.0051 - acc: 0.9986\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9995891170210366\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.99      0.99      2092\n",
      "       MISC       0.95      0.99      0.97      1215\n",
      "          O       1.00      1.00      1.00    420031\n",
      "        ORG       0.98      0.98      0.98      2067\n",
      "        PER       0.99      1.00      1.00      3139\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8434\n",
      "num_gold:  8513\n",
      "precision=0.9826\n",
      "recall=0.9907\n",
      "f1=0.9867\n",
      "final  .P0.98_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968880146646313\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.89      1955\n",
      "       MISC       0.71      0.82      0.76       794\n",
      "          O       1.00      1.00      1.00    448482\n",
      "        ORG       0.81      0.87      0.84      2326\n",
      "        PER       0.94      0.95      0.94      2763\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7013\n",
      "num_gold:  7838\n",
      "precision=0.8662\n",
      "recall=0.8947\n",
      "f1=0.8803\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 14 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0050 - acc: 0.9986\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999649119066199\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2118\n",
      "       MISC       0.96      0.99      0.98      1237\n",
      "          O       1.00      1.00      1.00    420008\n",
      "        ORG       0.97      0.99      0.98      2037\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8461\n",
      "num_gold:  8536\n",
      "precision=0.9858\n",
      "recall=0.9912\n",
      "f1=0.9885\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969138371208588\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.87      0.89      2005\n",
      "       MISC       0.73      0.80      0.76       830\n",
      "          O       1.00      1.00      1.00    448451\n",
      "        ORG       0.80      0.88      0.84      2245\n",
      "        PER       0.95      0.94      0.95      2789\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7028\n",
      "num_gold:  7869\n",
      "precision=0.8681\n",
      "recall=0.8931\n",
      "f1=0.8804\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 15 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 124s 107ms/step - loss: 0.0047 - acc: 0.9987\n",
      "216/216 [==============================] - 14s 63ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9996649634827435\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.99      0.99      2093\n",
      "       MISC       0.97      0.99      0.98      1239\n",
      "          O       1.00      1.00      1.00    420002\n",
      "        ORG       0.98      0.99      0.98      2066\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8470\n",
      "num_gold:  8542\n",
      "precision=0.9868\n",
      "recall=0.9916\n",
      "f1=0.9892\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 15s 63ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968431988707215\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1938\n",
      "       MISC       0.73      0.80      0.76       829\n",
      "          O       1.00      1.00      1.00    448407\n",
      "        ORG       0.81      0.86      0.83      2359\n",
      "        PER       0.95      0.94      0.94      2787\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7032\n",
      "num_gold:  7913\n",
      "precision=0.8686\n",
      "recall=0.8887\n",
      "f1=0.8785\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 16 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 125s 108ms/step - loss: 0.0046 - acc: 0.9987\n",
      "216/216 [==============================] - 13s 62ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9996422717877007\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2112\n",
      "       MISC       0.97      0.99      0.98      1239\n",
      "          O       1.00      1.00      1.00    420023\n",
      "        ORG       0.97      0.99      0.98      2030\n",
      "        PER       1.00      1.00      1.00      3140\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8453\n",
      "num_gold:  8521\n",
      "precision=0.9849\n",
      "recall=0.9920\n",
      "f1=0.9884\n",
      "final  .P0.98_R0.99_F0.99\n",
      "230/230 [==============================] - 14s 60ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968074209652443\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.88      0.89      1981\n",
      "       MISC       0.72      0.81      0.76       804\n",
      "          O       1.00      1.00      1.00    448519\n",
      "        ORG       0.78      0.88      0.83      2224\n",
      "        PER       0.95      0.94      0.94      2792\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6960\n",
      "num_gold:  7801\n",
      "precision=0.8597\n",
      "recall=0.8922\n",
      "f1=0.8756\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 17 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 122s 106ms/step - loss: 0.0044 - acc: 0.9987\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9996836147168433\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2105\n",
      "       MISC       0.97      0.99      0.98      1244\n",
      "          O       1.00      1.00      1.00    419998\n",
      "        ORG       0.98      0.99      0.98      2051\n",
      "        PER       1.00      1.00      1.00      3146\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8478\n",
      "num_gold:  8546\n",
      "precision=0.9878\n",
      "recall=0.9920\n",
      "f1=0.9899\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969015836444655\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1944\n",
      "       MISC       0.72      0.81      0.76       817\n",
      "          O       1.00      1.00      1.00    448486\n",
      "        ORG       0.79      0.87      0.83      2265\n",
      "        PER       0.95      0.94      0.94      2808\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7005\n",
      "num_gold:  7834\n",
      "precision=0.8652\n",
      "recall=0.8942\n",
      "f1=0.8795\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 18 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0040 - acc: 0.9989\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997115460834626\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2106\n",
      "       MISC       0.97      0.99      0.98      1242\n",
      "          O       1.00      1.00      1.00    419990\n",
      "        ORG       0.98      0.99      0.98      2053\n",
      "        PER       1.00      1.00      1.00      3153\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8488\n",
      "num_gold:  8554\n",
      "precision=0.9889\n",
      "recall=0.9923\n",
      "f1=0.9906\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968082332314717\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.88      0.89      1963\n",
      "       MISC       0.73      0.81      0.77       824\n",
      "          O       1.00      1.00      1.00    448443\n",
      "        ORG       0.79      0.86      0.82      2278\n",
      "        PER       0.95      0.94      0.94      2812\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6989\n",
      "num_gold:  7877\n",
      "precision=0.8633\n",
      "recall=0.8873\n",
      "f1=0.8751\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 19 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0039 - acc: 0.9989\n",
      "216/216 [==============================] - 12s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997328669208086\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2099\n",
      "       MISC       0.97      1.00      0.98      1230\n",
      "          O       1.00      1.00      1.00    420021\n",
      "        ORG       0.98      0.99      0.99      2054\n",
      "        PER       1.00      1.00      1.00      3140\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8480\n",
      "num_gold:  8523\n",
      "precision=0.9880\n",
      "recall=0.9950\n",
      "f1=0.9915\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968565834281566\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.90      0.90      1910\n",
      "       MISC       0.71      0.84      0.77       769\n",
      "          O       1.00      1.00      1.00    448555\n",
      "        ORG       0.79      0.86      0.82      2281\n",
      "        PER       0.95      0.94      0.94      2805\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6954\n",
      "num_gold:  7765\n",
      "precision=0.8589\n",
      "recall=0.8956\n",
      "f1=0.8769\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 20 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0038 - acc: 0.9989\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997627707028278\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2097\n",
      "       MISC       0.97      0.99      0.98      1241\n",
      "          O       1.00      1.00      1.00    420000\n",
      "        ORG       0.98      0.99      0.99      2055\n",
      "        PER       1.00      1.00      1.00      3151\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8500\n",
      "num_gold:  8544\n",
      "precision=0.9903\n",
      "recall=0.9949\n",
      "f1=0.9926\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 14s 62ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968504693088948\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.88      0.89      1967\n",
      "       MISC       0.71      0.83      0.77       783\n",
      "          O       1.00      1.00      1.00    448493\n",
      "        ORG       0.79      0.86      0.82      2287\n",
      "        PER       0.95      0.94      0.95      2790\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6977\n",
      "num_gold:  7827\n",
      "precision=0.8618\n",
      "recall=0.8914\n",
      "f1=0.8763\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 21 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 122s 106ms/step - loss: 0.0038 - acc: 0.9989\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997606338402909\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2098\n",
      "       MISC       0.97      1.00      0.98      1230\n",
      "          O       1.00      1.00      1.00    420013\n",
      "        ORG       0.99      0.99      0.99      2066\n",
      "        PER       1.00      1.00      1.00      3137\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8494\n",
      "num_gold:  8531\n",
      "precision=0.9896\n",
      "recall=0.9957\n",
      "f1=0.9926\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 14s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969120454722348\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1926\n",
      "       MISC       0.70      0.86      0.77       738\n",
      "          O       1.00      1.00      1.00    448578\n",
      "        ORG       0.80      0.86      0.83      2331\n",
      "        PER       0.94      0.95      0.94      2747\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6963\n",
      "num_gold:  7742\n",
      "precision=0.8601\n",
      "recall=0.8994\n",
      "f1=0.8793\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 22 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0037 - acc: 0.9989\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997974083263745\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2098\n",
      "       MISC       0.98      0.99      0.99      1246\n",
      "          O       1.00      1.00      1.00    419981\n",
      "        ORG       0.99      0.99      0.99      2071\n",
      "        PER       1.00      1.00      1.00      3148\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8515\n",
      "num_gold:  8563\n",
      "precision=0.9921\n",
      "recall=0.9944\n",
      "f1=0.9932\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969277819581844\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1921\n",
      "       MISC       0.72      0.82      0.77       800\n",
      "          O       1.00      1.00      1.00    448404\n",
      "        ORG       0.82      0.86      0.84      2377\n",
      "        PER       0.95      0.94      0.95      2818\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7057\n",
      "num_gold:  7916\n",
      "precision=0.8717\n",
      "recall=0.8915\n",
      "f1=0.8815\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 23 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0034 - acc: 0.9990\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997835504310025\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2107\n",
      "       MISC       0.98      1.00      0.99      1240\n",
      "          O       1.00      1.00      1.00    419992\n",
      "        ORG       0.98      0.99      0.99      2062\n",
      "        PER       1.00      1.00      1.00      3143\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8509\n",
      "num_gold:  8552\n",
      "precision=0.9914\n",
      "recall=0.9950\n",
      "f1=0.9932\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969062712034258\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1926\n",
      "       MISC       0.71      0.83      0.76       780\n",
      "          O       1.00      1.00      1.00    448485\n",
      "        ORG       0.81      0.86      0.83      2344\n",
      "        PER       0.95      0.94      0.94      2785\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7010\n",
      "num_gold:  7835\n",
      "precision=0.8659\n",
      "recall=0.8947\n",
      "f1=0.8800\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 24 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0034 - acc: 0.9990\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997812958219313\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2099\n",
      "       MISC       0.98      1.00      0.99      1242\n",
      "          O       1.00      1.00      1.00    420006\n",
      "        ORG       0.98      0.99      0.99      2058\n",
      "        PER       1.00      1.00      1.00      3139\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8501\n",
      "num_gold:  8538\n",
      "precision=0.9904\n",
      "recall=0.9957\n",
      "f1=0.9930\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969371320911121\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.89      0.89      1922\n",
      "       MISC       0.72      0.83      0.77       795\n",
      "          O       1.00      1.00      1.00    448583\n",
      "        ORG       0.80      0.87      0.83      2269\n",
      "        PER       0.94      0.95      0.95      2751\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6964\n",
      "num_gold:  7737\n",
      "precision=0.8602\n",
      "recall=0.9001\n",
      "f1=0.8797\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 25 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0034 - acc: 0.9990\n",
      "216/216 [==============================] - 12s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997971684488277\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.99      0.99      0.99      2093\n",
      "       MISC       0.98      0.99      0.99      1257\n",
      "          O       1.00      1.00      1.00    419972\n",
      "        ORG       0.99      0.99      0.99      2075\n",
      "        PER       1.00      1.00      1.00      3147\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8520\n",
      "num_gold:  8572\n",
      "precision=0.9927\n",
      "recall=0.9939\n",
      "f1=0.9933\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969147327735749\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.88      0.91      0.90      1855\n",
      "       MISC       0.73      0.81      0.77       828\n",
      "          O       1.00      1.00      1.00    448467\n",
      "        ORG       0.82      0.85      0.84      2407\n",
      "        PER       0.94      0.94      0.94      2763\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7026\n",
      "num_gold:  7853\n",
      "precision=0.8678\n",
      "recall=0.8947\n",
      "f1=0.8811\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 26 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0033 - acc: 0.9991\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998088697158494\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2102\n",
      "       MISC       0.99      0.99      0.99      1259\n",
      "          O       1.00      1.00      1.00    419971\n",
      "        ORG       0.99      0.99      0.99      2064\n",
      "        PER       1.00      1.00      1.00      3148\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8524\n",
      "num_gold:  8573\n",
      "precision=0.9931\n",
      "recall=0.9943\n",
      "f1=0.9937\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969555382808309\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.91      0.90      1871\n",
      "       MISC       0.72      0.82      0.76       801\n",
      "          O       1.00      1.00      1.00    448486\n",
      "        ORG       0.81      0.86      0.84      2350\n",
      "        PER       0.95      0.94      0.94      2812\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7028\n",
      "num_gold:  7834\n",
      "precision=0.8681\n",
      "recall=0.8971\n",
      "f1=0.8824\n",
      "final  .P0.87_R0.90_F0.88\n",
      "=== EPOCH 27 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0033 - acc: 0.9991\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998299194384316\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2093\n",
      "       MISC       0.99      1.00      0.99      1252\n",
      "          O       1.00      1.00      1.00    419986\n",
      "        ORG       0.99      0.99      0.99      2069\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8526\n",
      "num_gold:  8558\n",
      "precision=0.9934\n",
      "recall=0.9963\n",
      "f1=0.9948\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969461369129586\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.90      0.90      1907\n",
      "       MISC       0.72      0.83      0.77       787\n",
      "          O       1.00      1.00      1.00    448494\n",
      "        ORG       0.81      0.86      0.84      2346\n",
      "        PER       0.95      0.95      0.95      2786\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7030\n",
      "num_gold:  7826\n",
      "precision=0.8683\n",
      "recall=0.8983\n",
      "f1=0.8831\n",
      "final  .P0.87_R0.90_F0.88\n",
      "=== EPOCH 28 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0031 - acc: 0.9991\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999846452320084\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2099\n",
      "       MISC       0.98      1.00      0.99      1246\n",
      "          O       1.00      1.00      1.00    419998\n",
      "        ORG       0.99      1.00      0.99      2057\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8521\n",
      "num_gold:  8546\n",
      "precision=0.9928\n",
      "recall=0.9971\n",
      "f1=0.9949\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968846696509479\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1916\n",
      "       MISC       0.71      0.83      0.77       774\n",
      "          O       1.00      1.00      1.00    448560\n",
      "        ORG       0.80      0.87      0.83      2301\n",
      "        PER       0.94      0.94      0.94      2769\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6974\n",
      "num_gold:  7760\n",
      "precision=0.8614\n",
      "recall=0.8987\n",
      "f1=0.8797\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 29 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0030 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998741279802611\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2100\n",
      "       MISC       0.99      1.00      0.99      1263\n",
      "          O       1.00      1.00      1.00    419978\n",
      "        ORG       0.99      1.00      0.99      2063\n",
      "        PER       1.00      1.00      1.00      3140\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8540\n",
      "num_gold:  8566\n",
      "precision=0.9950\n",
      "recall=0.9970\n",
      "f1=0.9960\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969186269761796\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1917\n",
      "       MISC       0.74      0.79      0.76       851\n",
      "          O       1.00      1.00      1.00    448470\n",
      "        ORG       0.80      0.87      0.83      2299\n",
      "        PER       0.95      0.94      0.95      2783\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7023\n",
      "num_gold:  7850\n",
      "precision=0.8675\n",
      "recall=0.8946\n",
      "f1=0.8808\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 30 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0030 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998299399583918\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2103\n",
      "       MISC       0.99      1.00      0.99      1252\n",
      "          O       1.00      1.00      1.00    419989\n",
      "        ORG       0.99      0.99      0.99      2064\n",
      "        PER       1.00      1.00      1.00      3136\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8525\n",
      "num_gold:  8555\n",
      "precision=0.9932\n",
      "recall=0.9965\n",
      "f1=0.9949\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968227422798379\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.89      1982\n",
      "       MISC       0.73      0.80      0.76       827\n",
      "          O       1.00      1.00      1.00    448494\n",
      "        ORG       0.80      0.87      0.83      2288\n",
      "        PER       0.94      0.95      0.94      2729\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6981\n",
      "num_gold:  7826\n",
      "precision=0.8623\n",
      "recall=0.8920\n",
      "f1=0.8769\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 31 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0030 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998251974375654\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2108\n",
      "       MISC       0.98      0.99      0.99      1253\n",
      "          O       1.00      1.00      1.00    419976\n",
      "        ORG       0.99      0.99      0.99      2069\n",
      "        PER       1.00      1.00      1.00      3138\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8525\n",
      "num_gold:  8568\n",
      "precision=0.9932\n",
      "recall=0.9950\n",
      "f1=0.9941\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968711750760331\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.89      1971\n",
      "       MISC       0.73      0.79      0.76       836\n",
      "          O       1.00      1.00      1.00    448421\n",
      "        ORG       0.81      0.86      0.83      2347\n",
      "        PER       0.94      0.95      0.95      2745\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7028\n",
      "num_gold:  7899\n",
      "precision=0.8681\n",
      "recall=0.8897\n",
      "f1=0.8788\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 32 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0030 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998184856506575\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2112\n",
      "       MISC       0.99      1.00      0.99      1253\n",
      "          O       1.00      1.00      1.00    419992\n",
      "        ORG       0.98      1.00      0.99      2043\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8517\n",
      "num_gold:  8552\n",
      "precision=0.9923\n",
      "recall=0.9959\n",
      "f1=0.9941\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968993876712018\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.92      0.87      0.89      2014\n",
      "       MISC       0.72      0.82      0.77       799\n",
      "          O       1.00      1.00      1.00    448530\n",
      "        ORG       0.77      0.89      0.83      2159\n",
      "        PER       0.95      0.94      0.95      2818\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6987\n",
      "num_gold:  7790\n",
      "precision=0.8630\n",
      "recall=0.8969\n",
      "f1=0.8796\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 33 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0028 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998600854023387\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2094\n",
      "       MISC       0.99      1.00      0.99      1255\n",
      "          O       1.00      1.00      1.00    419973\n",
      "        ORG       0.99      0.99      0.99      2077\n",
      "        PER       1.00      1.00      1.00      3145\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8537\n",
      "num_gold:  8571\n",
      "precision=0.9946\n",
      "recall=0.9960\n",
      "f1=0.9953\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969363188347735\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.89      0.89      1926\n",
      "       MISC       0.73      0.81      0.77       827\n",
      "          O       1.00      1.00      1.00    448385\n",
      "        ORG       0.82      0.86      0.84      2370\n",
      "        PER       0.95      0.94      0.95      2812\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7074\n",
      "num_gold:  7935\n",
      "precision=0.8738\n",
      "recall=0.8915\n",
      "f1=0.8825\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 34 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0028 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998880435825861\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2096\n",
      "       MISC       0.99      1.00      0.99      1263\n",
      "          O       1.00      1.00      1.00    419971\n",
      "        ORG       0.99      1.00      0.99      2076\n",
      "        PER       1.00      1.00      1.00      3138\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8548\n",
      "num_gold:  8573\n",
      "precision=0.9959\n",
      "recall=0.9971\n",
      "f1=0.9965\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968923165052722\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.88      0.89      1953\n",
      "       MISC       0.72      0.79      0.75       839\n",
      "          O       1.00      1.00      1.00    448420\n",
      "        ORG       0.81      0.87      0.84      2335\n",
      "        PER       0.95      0.95      0.95      2773\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7031\n",
      "num_gold:  7900\n",
      "precision=0.8685\n",
      "recall=0.8900\n",
      "f1=0.8791\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 35 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0028 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998648606721068\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2102\n",
      "       MISC       0.99      1.00      0.99      1255\n",
      "          O       1.00      1.00      1.00    419984\n",
      "        ORG       0.99      1.00      0.99      2063\n",
      "        PER       1.00      1.00      1.00      3140\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8536\n",
      "num_gold:  8560\n",
      "precision=0.9945\n",
      "recall=0.9972\n",
      "f1=0.9959\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968866377584663\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.89      1940\n",
      "       MISC       0.71      0.81      0.76       802\n",
      "          O       1.00      1.00      1.00    448573\n",
      "        ORG       0.79      0.88      0.83      2242\n",
      "        PER       0.94      0.95      0.94      2763\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6960\n",
      "num_gold:  7747\n",
      "precision=0.8597\n",
      "recall=0.8984\n",
      "f1=0.8786\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 36 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0027 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998463346566523\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2096\n",
      "       MISC       0.99      1.00      0.99      1253\n",
      "          O       1.00      1.00      1.00    419997\n",
      "        ORG       0.99      1.00      0.99      2058\n",
      "        PER       1.00      1.00      1.00      3140\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8523\n",
      "num_gold:  8547\n",
      "precision=0.9930\n",
      "recall=0.9972\n",
      "f1=0.9951\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969266280636191\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.90      0.89      1914\n",
      "       MISC       0.71      0.82      0.76       794\n",
      "          O       1.00      1.00      1.00    448477\n",
      "        ORG       0.80      0.88      0.84      2271\n",
      "        PER       0.96      0.93      0.94      2864\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7017\n",
      "num_gold:  7843\n",
      "precision=0.8667\n",
      "recall=0.8947\n",
      "f1=0.8805\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 37 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0028 - acc: 0.9992\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998071328591823\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2107\n",
      "       MISC       0.99      1.00      0.99      1261\n",
      "          O       1.00      1.00      1.00    420009\n",
      "        ORG       0.97      1.00      0.99      2028\n",
      "        PER       1.00      1.00      1.00      3139\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8508\n",
      "num_gold:  8535\n",
      "precision=0.9913\n",
      "recall=0.9968\n",
      "f1=0.9940\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969110652744383\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.89      1972\n",
      "       MISC       0.72      0.80      0.76       825\n",
      "          O       1.00      1.00      1.00    448568\n",
      "        ORG       0.78      0.89      0.83      2185\n",
      "        PER       0.95      0.95      0.95      2770\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6969\n",
      "num_gold:  7752\n",
      "precision=0.8608\n",
      "recall=0.8990\n",
      "f1=0.8795\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 38 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0027 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998186067515304\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2103\n",
      "       MISC       0.99      1.00      0.99      1254\n",
      "          O       1.00      1.00      1.00    420009\n",
      "        ORG       0.98      1.00      0.99      2039\n",
      "        PER       1.00      1.00      1.00      3139\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8512\n",
      "num_gold:  8535\n",
      "precision=0.9917\n",
      "recall=0.9973\n",
      "f1=0.9945\n",
      "final  .P0.99_R1.00_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969047257948388\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1925\n",
      "       MISC       0.72      0.80      0.76       815\n",
      "          O       1.00      1.00      1.00    448590\n",
      "        ORG       0.78      0.89      0.83      2181\n",
      "        PER       0.95      0.94      0.95      2809\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6959\n",
      "num_gold:  7730\n",
      "precision=0.8596\n",
      "recall=0.9003\n",
      "f1=0.8794\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 39 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0026 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9997999314776221\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      0.99      2112\n",
      "       MISC       0.99      0.99      0.99      1259\n",
      "          O       1.00      1.00      1.00    419990\n",
      "        ORG       0.98      1.00      0.99      2034\n",
      "        PER       1.00      1.00      1.00      3149\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8511\n",
      "num_gold:  8554\n",
      "precision=0.9916\n",
      "recall=0.9950\n",
      "f1=0.9933\n",
      "final  .P0.99_R0.99_F0.99\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.996854864971837\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1959\n",
      "       MISC       0.72      0.80      0.76       818\n",
      "          O       1.00      1.00      1.00    448531\n",
      "        ORG       0.77      0.89      0.82      2162\n",
      "        PER       0.96      0.93      0.95      2850\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6970\n",
      "num_gold:  7789\n",
      "precision=0.8609\n",
      "recall=0.8949\n",
      "f1=0.8776\n",
      "final  .P0.86_R0.89_F0.88\n",
      "=== EPOCH 40 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0025 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998648086230798\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2100\n",
      "       MISC       0.99      1.00      0.99      1258\n",
      "          O       1.00      1.00      1.00    419982\n",
      "        ORG       0.99      0.99      0.99      2069\n",
      "        PER       1.00      1.00      1.00      3135\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8536\n",
      "num_gold:  8562\n",
      "precision=0.9945\n",
      "recall=0.9970\n",
      "f1=0.9957\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969315930323683\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.89      0.90      1968\n",
      "       MISC       0.72      0.81      0.76       816\n",
      "          O       1.00      1.00      1.00    448570\n",
      "        ORG       0.79      0.87      0.83      2266\n",
      "        PER       0.93      0.96      0.95      2700\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6976\n",
      "num_gold:  7750\n",
      "precision=0.8617\n",
      "recall=0.9001\n",
      "f1=0.8805\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 41 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0025 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999878778111704\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2099\n",
      "       MISC       0.99      0.99      0.99      1266\n",
      "          O       1.00      1.00      1.00    419976\n",
      "        ORG       0.99      0.99      0.99      2066\n",
      "        PER       1.00      1.00      1.00      3137\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8541\n",
      "num_gold:  8568\n",
      "precision=0.9951\n",
      "recall=0.9968\n",
      "f1=0.9960\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968823477431753\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.89      0.90      1962\n",
      "       MISC       0.73      0.80      0.76       831\n",
      "          O       1.00      1.00      1.00    448468\n",
      "        ORG       0.80      0.87      0.83      2290\n",
      "        PER       0.94      0.94      0.94      2769\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7004\n",
      "num_gold:  7852\n",
      "precision=0.8651\n",
      "recall=0.8920\n",
      "f1=0.8784\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 42 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0025 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999904388702487\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2096\n",
      "       MISC       0.99      1.00      0.99      1262\n",
      "          O       1.00      1.00      1.00    419971\n",
      "        ORG       0.99      1.00      1.00      2071\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8552\n",
      "num_gold:  8573\n",
      "precision=0.9964\n",
      "recall=0.9976\n",
      "f1=0.9970\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968842704581093\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.89      0.90      1955\n",
      "       MISC       0.72      0.79      0.76       826\n",
      "          O       1.00      1.00      1.00    448433\n",
      "        ORG       0.80      0.86      0.83      2329\n",
      "        PER       0.95      0.94      0.95      2777\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7031\n",
      "num_gold:  7887\n",
      "precision=0.8685\n",
      "recall=0.8915\n",
      "f1=0.8798\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 43 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0025 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998903391425382\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2092\n",
      "       MISC       0.99      1.00      1.00      1257\n",
      "          O       1.00      1.00      1.00    419967\n",
      "        ORG       0.99      0.99      0.99      2084\n",
      "        PER       1.00      1.00      1.00      3144\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8550\n",
      "num_gold:  8577\n",
      "precision=0.9962\n",
      "recall=0.9969\n",
      "f1=0.9965\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969194657366502\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.90      0.90      1886\n",
      "       MISC       0.73      0.81      0.77       818\n",
      "          O       1.00      1.00      1.00    448436\n",
      "        ORG       0.82      0.86      0.84      2375\n",
      "        PER       0.95      0.94      0.94      2805\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7037\n",
      "num_gold:  7884\n",
      "precision=0.8692\n",
      "recall=0.8926\n",
      "f1=0.8807\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 44 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0024 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998809865512304\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2090\n",
      "       MISC       0.99      1.00      1.00      1261\n",
      "          O       1.00      1.00      1.00    419972\n",
      "        ORG       0.99      0.99      0.99      2086\n",
      "        PER       1.00      1.00      1.00      3135\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8543\n",
      "num_gold:  8572\n",
      "precision=0.9953\n",
      "recall=0.9966\n",
      "f1=0.9960\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969033916286936\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.89      0.91      0.90      1882\n",
      "       MISC       0.72      0.81      0.76       807\n",
      "          O       1.00      1.00      1.00    448475\n",
      "        ORG       0.82      0.85      0.83      2409\n",
      "        PER       0.94      0.95      0.95      2747\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7015\n",
      "num_gold:  7845\n",
      "precision=0.8665\n",
      "recall=0.8942\n",
      "f1=0.8801\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 45 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 119s 104ms/step - loss: 0.0024 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 58ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.999867219532793\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2099\n",
      "       MISC       0.99      1.00      0.99      1259\n",
      "          O       1.00      1.00      1.00    419992\n",
      "        ORG       0.99      1.00      0.99      2058\n",
      "        PER       1.00      1.00      1.00      3136\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8534\n",
      "num_gold:  8552\n",
      "precision=0.9943\n",
      "recall=0.9979\n",
      "f1=0.9961\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969193965589436\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1919\n",
      "       MISC       0.72      0.81      0.76       805\n",
      "          O       1.00      1.00      1.00    448492\n",
      "        ORG       0.81      0.86      0.83      2361\n",
      "        PER       0.94      0.95      0.95      2743\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7014\n",
      "num_gold:  7828\n",
      "precision=0.8664\n",
      "recall=0.8960\n",
      "f1=0.8809\n",
      "final  .P0.87_R0.90_F0.88\n",
      "=== EPOCH 46 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 120s 104ms/step - loss: 0.0026 - acc: 0.9993\n",
      "216/216 [==============================] - 13s 59ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998765324973535\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2102\n",
      "       MISC       0.99      1.00      0.99      1260\n",
      "          O       1.00      1.00      1.00    419979\n",
      "        ORG       0.99      1.00      0.99      2056\n",
      "        PER       1.00      1.00      1.00      3147\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8539\n",
      "num_gold:  8565\n",
      "precision=0.9949\n",
      "recall=0.9970\n",
      "f1=0.9959\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 13s 58ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968992345280012\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.89      1954\n",
      "       MISC       0.73      0.80      0.76       828\n",
      "          O       1.00      1.00      1.00    448517\n",
      "        ORG       0.78      0.89      0.83      2175\n",
      "        PER       0.96      0.93      0.95      2846\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6984\n",
      "num_gold:  7803\n",
      "precision=0.8626\n",
      "recall=0.8950\n",
      "f1=0.8785\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 47 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 125s 108ms/step - loss: 0.0024 - acc: 0.9994\n",
      "216/216 [==============================] - 14s 63ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998717041396258\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2110\n",
      "       MISC       0.99      0.99      0.99      1266\n",
      "          O       1.00      1.00      1.00    419966\n",
      "        ORG       0.99      1.00      0.99      2061\n",
      "        PER       1.00      1.00      1.00      3141\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8545\n",
      "num_gold:  8578\n",
      "precision=0.9956\n",
      "recall=0.9962\n",
      "f1=0.9959\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 15s 64ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9967799276671582\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.92      0.86      0.89      2046\n",
      "       MISC       0.73      0.79      0.76       845\n",
      "          O       1.00      1.00      1.00    448404\n",
      "        ORG       0.78      0.88      0.83      2231\n",
      "        PER       0.95      0.94      0.94      2794\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7007\n",
      "num_gold:  7916\n",
      "precision=0.8655\n",
      "recall=0.8852\n",
      "f1=0.8752\n",
      "final  .P0.87_R0.89_F0.88\n",
      "=== EPOCH 48 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 125s 108ms/step - loss: 0.0024 - acc: 0.9993\n",
      "216/216 [==============================] - 14s 63ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998741362521466\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      0.99      1.00      2109\n",
      "       MISC       0.99      1.00      0.99      1256\n",
      "          O       1.00      1.00      1.00    419974\n",
      "        ORG       0.99      1.00      0.99      2062\n",
      "        PER       1.00      1.00      1.00      3143\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8540\n",
      "num_gold:  8570\n",
      "precision=0.9950\n",
      "recall=0.9965\n",
      "f1=0.9957\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 15s 64ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9969253886350046\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.91      0.88      0.90      1988\n",
      "       MISC       0.71      0.85      0.77       761\n",
      "          O       1.00      1.00      1.00    448538\n",
      "        ORG       0.79      0.88      0.83      2249\n",
      "        PER       0.95      0.94      0.95      2784\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6988\n",
      "num_gold:  7782\n",
      "precision=0.8631\n",
      "recall=0.8980\n",
      "f1=0.8802\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 49 ===\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153/1153 [==============================] - 122s 105ms/step - loss: 0.0023 - acc: 0.9994\n",
      "216/216 [==============================] - 13s 60ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9998695883363811\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2101\n",
      "       MISC       0.99      1.00      0.99      1250\n",
      "          O       1.00      1.00      1.00    419995\n",
      "        ORG       0.99      1.00      0.99      2061\n",
      "        PER       1.00      1.00      1.00      3137\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8533\n",
      "num_gold:  8549\n",
      "precision=0.9942\n",
      "recall=0.9981\n",
      "f1=0.9961\n",
      "final  .P0.99_R1.00_F1.00\n",
      "230/230 [==============================] - 14s 59ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.9968659735446297\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.89      0.90      1946\n",
      "       MISC       0.71      0.81      0.76       801\n",
      "          O       1.00      1.00      1.00    448567\n",
      "        ORG       0.79      0.87      0.83      2272\n",
      "        PER       0.94      0.95      0.95      2734\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  6965\n",
      "num_gold:  7753\n",
      "precision=0.8603\n",
      "recall=0.8984\n",
      "f1=0.8789\n",
      "final  .P0.86_R0.90_F0.88\n",
      "=== EPOCH 50 ===\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 121s 105ms/step - loss: 0.0023 - acc: 0.9994\n",
      "216/216 [==============================] - 13s 60ms/step\n",
      "=== Validation Results ===\n",
      "Weighted F1-score:  0.9999066632147694\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       1.00      1.00      1.00      2101\n",
      "       MISC       0.99      1.00      1.00      1262\n",
      "          O       1.00      1.00      1.00    419964\n",
      "        ORG       0.99      0.99      0.99      2079\n",
      "        PER       1.00      1.00      1.00      3138\n",
      "\n",
      "avg / total       1.00      1.00      1.00    428544\n",
      "\n",
      "num_proposed:  8583\n",
      "num_correct:  8554\n",
      "num_gold:  8580\n",
      "precision=0.9966\n",
      "recall=0.9970\n",
      "f1=0.9968\n",
      "final  .P1.00_R1.00_F1.00\n",
      "230/230 [==============================] - 14s 60ms/step\n",
      "=== Test Results ===\n",
      "Weighted F1-score:  0.996795487558708\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.90      0.90      0.90      1924\n",
      "       MISC       0.72      0.82      0.76       799\n",
      "          O       1.00      1.00      1.00    448405\n",
      "        ORG       0.82      0.83      0.83      2465\n",
      "        PER       0.93      0.95      0.94      2727\n",
      "\n",
      "avg / total       1.00      1.00      1.00    456320\n",
      "\n",
      "num_proposed:  8096\n",
      "num_correct:  7015\n",
      "num_gold:  7915\n",
      "precision=0.8665\n",
      "recall=0.8863\n",
      "f1=0.8763\n",
      "final  .P0.87_R0.89_F0.88\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(\"=== EPOCH {} ===\".format(epoch + 1))\n",
    "\n",
    "    model.fit_generator(batch_generator(A, X, Y, 'train', batch_size=BATCH_SIZE),\n",
    "                        steps_per_epoch=len(A['train'])//BATCH_SIZE, verbose=1)\n",
    "\n",
    "\n",
    "    val_predictions = model.predict_generator(batch_generator(\n",
    "        A, X, Y, 'val', batch_size=BATCH_SIZE), steps=len(A['val'])//BATCH_SIZE, verbose=1)\n",
    "    val_predicted_labels, val_actual_labels = predict_labels(\n",
    "        val_predictions, val_y, meta['idx2label'])\n",
    "\n",
    "    for i in range(len(val_predicted_labels)):\n",
    "        val_predicted_labels[i] = [x.split('-')[1] if '-' in x else x for x in val_predicted_labels[i]]\n",
    "    for i in range(len(val_actual_labels)):\n",
    "        val_actual_labels[i] = [x.split('-')[1] if '-' in x else x for x in val_actual_labels[i]]\n",
    "    \n",
    "    gt = []\n",
    "    pr = []\n",
    "    for i in range(len(val_predicted_labels)):\n",
    "        gt.extend(val_predicted_labels[i])\n",
    "    for i in range(len(val_actual_labels)):\n",
    "        pr.extend(val_actual_labels[i])\n",
    "        \n",
    "    print(\"=== Validation Results ===\")\n",
    "    print(\"Weighted F1-score: \",f1_score(gt,pr, average = 'weighted'))\n",
    "    print(\"Classification report:\\n\", classification_report(gt,pr))\n",
    "    evaluate_metrics(gt, pr)\n",
    "\n",
    "    test_predictions = model.predict_generator(batch_generator(\n",
    "        A, X, Y, 'test', batch_size=BATCH_SIZE), steps=len(A['test']) // BATCH_SIZE, verbose=1)\n",
    "\n",
    "    test_predicted_labels, test_actual_labels = predict_labels(\n",
    "        test_predictions, test_y, meta['idx2label'])\n",
    "    for i in range(len(test_predicted_labels)):\n",
    "        test_predicted_labels[i] = [x.split('-')[1] if '-' in x else x for x in test_predicted_labels[i]]\n",
    "    for i in range(len(test_actual_labels)):\n",
    "        test_actual_labels[i] = [x.split('-')[1] if '-' in x else x for x in test_actual_labels[i]]\n",
    "\n",
    "    print(\"=== Test Results ===\")\n",
    "\n",
    "    gt = []\n",
    "    pr = []\n",
    "    for i in range(len(test_predicted_labels)):\n",
    "        gt.extend(test_predicted_labels[i])\n",
    "    for i in range(len(test_actual_labels)):\n",
    "        pr.extend(test_actual_labels[i])\n",
    "    print(\"Weighted F1-score: \",f1_score(gt,pr, average = 'weighted'))\n",
    "    print(\"Classification report:\\n\", classification_report(gt,pr))\n",
    "    evaluate_metrics(gt, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
